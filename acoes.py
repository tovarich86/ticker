import streamlit as st
import requests
import pandas as pd
import yfinance as yf
from base64 import b64encode
from datetime import datetime, timedelta
import json
import re
import time 

# --- IMPORTAﾃﾃグ ADICIONADA ---
# Importa curl_cffi para criar sessﾃ｣o com fingerprint de navegador
from curl_cffi import requests as curl_requests
from requests.cookies import create_cookie
import yfinance.data as _data


# URL do arquivo no GitHub
URL_EMPRESAS = "https://github.com/tovarich86/ticker/raw/refs/heads/main/empresas_b3%20(6).xlsx"

@st.cache_data
def carregar_empresas():
    """Carrega e prﾃｩ-processa o DataFrame de empresas a partir de um arquivo Excel."""
    try:
        df_empresas = pd.read_excel(URL_EMPRESAS)

        # Padronizar colunas de texto e remover espaﾃｧos extras
        cols_to_process = ['Nome do Pregﾃ｣o', 'Tickers', 'CODE', 'typeStock']
        for col in cols_to_process:
            if col in df_empresas.columns:
                # Garantir que a coluna seja string e preencher NaNs com string vazia
                df_empresas[col] = df_empresas[col].astype(str).fillna('')
                # Remover espaﾃｧos extras no inﾃｭcio/fim
                df_empresas[col] = df_empresas[col].str.strip()
                # Padronizar Nome do Pregﾃ｣o para S.A. e maiﾃｺsculas
                if col == 'Nome do Pregﾃ｣o':
                    df_empresas[col] = df_empresas[col].str.replace(r'\s*S\.?A\.?/A?', ' S.A.', regex=True).str.upper().str.strip()
                # Padronizar typeStock para maiﾃｺsculas
                if col == 'typeStock':
                    df_empresas[col] = df_empresas[col].str.upper()

        # Remover linhas onde Tickers ou Nome do Pregﾃ｣o estﾃ｣o vazios apﾃｳs limpeza
        df_empresas = df_empresas[df_empresas['Tickers'] != '']
        df_empresas = df_empresas[df_empresas['Nome do Pregﾃ｣o'] != '']

        return df_empresas
    except Exception as e:
        st.error(f"Erro ao carregar ou processar a planilha de empresas: {e}")
        return pd.DataFrame() # Retorna DataFrame vazio em caso de erro

def get_ticker_info(ticker, empresas_df):
    """
    Busca informaﾃｧﾃｵes de um ticker (Nome do Pregﾃ｣o, CODE, typeStock) na planilha de empresas.
    Retorna um dicionﾃ｡rio com as informaﾃｧﾃｵes ou None se nﾃ｣o encontrado.
    """
    ticker_upper = ticker.strip().upper()
    for index, row in empresas_df.iterrows():
        # Divide a string de tickers, remove espaﾃｧos e converte para maiﾃｺsculas
        tickers_list = [t.strip().upper() for t in row['Tickers'].split(",") if t.strip()]
        if ticker_upper in tickers_list:
            return {
                'trading_name': row['Nome do Pregﾃ｣o'],
                'code': row['CODE'],
                'type_stock': row['typeStock']
            }
    return None  # Retorna None se o ticker nﾃ｣o for encontrado

# --- Funﾃｧﾃ｣o de Busca de Dividendos (MODIFICADA) ---
def buscar_dividendos_b3(ticker, empresas_df, data_inicio, data_fim):
    """
    Busca dividendos na B3 para um ticker especﾃｭfico, tratando paginaﾃｧﾃ｣o
    e filtrando pelo typeStock correto (ON, PN, UNT).
    Retorna um DataFrame com os dividendos filtrados ou DataFrame vazio.
    """
    if not any(char.isdigit() for char in ticker):
        return pd.DataFrame()

    ticker_info = get_ticker_info(ticker, empresas_df)

    if not ticker_info:
        st.warning(f"Informaﾃｧﾃｵes nﾃ｣o encontradas para o ticker {ticker} na planilha de empresas.")
        return pd.DataFrame()

    trading_name = ticker_info['trading_name']
    desired_type_stock = ticker_info['type_stock']

    if not trading_name:
        st.warning(f"Nome de pregﾃ｣o nﾃ｣o encontrado para o ticker {ticker}.")
        return pd.DataFrame()
    if not desired_type_stock:
        st.warning(f"Tipo de aﾃｧﾃ｣o (typeStock) nﾃ｣o encontrado para o ticker {ticker} na planilha.")
        return pd.DataFrame()

    all_dividends = []
    current_page = 1
    total_pages = 1

    st.write(f"Buscando dividendos para {ticker} ({trading_name}, Tipo: {desired_type_stock})...")

    # --- ALTERAﾃﾃグ AQUI: Usa curl_cffi ---
    session = curl_requests.Session(impersonate="chrome")
    
    while current_page <= total_pages:
        try:
            params = {
                "language": "pt-br",
                "pageNumber": str(current_page),
                "pageSize": "50",
                "tradingName": trading_name,
            }
            params_json = json.dumps(params)
            params_encoded = b64encode(params_json.encode('utf-8')).decode('utf-8')
            url = f'https://sistemaswebb3-listados.b3.com.br/listedCompaniesProxy/CompanyCall/GetListedCashDividends/{params_encoded}'

            # --- ALTERAﾃﾃグ AQUI: Usa a sessﾃ｣o para fazer a requisiﾃｧﾃ｣o ---
            response = session.get(url, timeout=30)
            response.raise_for_status()
            response_json = response.json()

            if current_page == 1 and 'page' in response_json and 'totalPages' in response_json['page']:
                total_pages = int(response_json['page']['totalPages'])
                st.write(f"Total de {total_pages} pﾃ｡ginas de dividendos encontradas para {trading_name}.")

            if 'results' in response_json and response_json['results']:
                all_dividends.extend(response_json['results'])
            elif current_page == 1:
                break

            if total_pages > 1:
                time.sleep(0.5)

            current_page += 1

        # --- ALTERAﾃﾃグ AQUI: Captura o erro da biblioteca correta ---
        except curl_requests.errors.RequestsError as e:
            st.error(f"Erro de rede ao buscar dividendos para {ticker} (pﾃ｡gina {current_page}): {e}")
            break
        except json.JSONDecodeError:
            st.error(f"Erro ao decodificar JSON da resposta da B3 para {ticker} (pﾃ｡gina {current_page}).")
            break
        except Exception as e:
            st.error(f"Erro inesperado ao buscar dividendos para {ticker} (pﾃ｡gina {current_page}): {e}")
            break

    if not all_dividends:
        return pd.DataFrame()

    df = pd.DataFrame(all_dividends)
    if 'typeStock' in df.columns:
        df['typeStock'] = df['typeStock'].str.strip().str.upper()
        df_filtered_type = df[df['typeStock'] == desired_type_stock].copy()
        if df_filtered_type.empty:
            return pd.DataFrame()
        df = df_filtered_type
    else:
        st.warning(f"Coluna 'typeStock' nﾃ｣o encontrada nos resultados da B3 para {ticker}. Nﾃ｣o foi possﾃｭvel filtrar por tipo de aﾃｧﾃ｣o.")

    df['Ticker'] = ticker

    if 'lastDatePriorEx' in df.columns:
        df['lastDatePriorEx_dt'] = pd.to_datetime(df['lastDatePriorEx'], format='%d/%m/%Y', errors='coerce')
        df = df.dropna(subset=['lastDatePriorEx_dt'])
        df = df[(df['lastDatePriorEx_dt'] >= data_inicio) & (df['lastDatePriorEx_dt'] <= data_fim)]
        df = df.drop(columns=['lastDatePriorEx_dt'])
    else:
        st.warning(f"Coluna 'lastDatePriorEx' nﾃ｣o encontrada para filtrar datas de dividendos de {ticker}.")
        return pd.DataFrame()

    if 'Ticker' in df.columns:
        cols_to_keep = ['Ticker', 'paymentDate', 'typeStock', 'lastDatePriorEx', 'value', 'relatedToAction', 'label', 'ratio']
        existing_cols_to_keep = [col for col in cols_to_keep if col in df.columns]
        other_cols = [col for col in df.columns if col not in existing_cols_to_keep]
        df = df[existing_cols_to_keep + other_cols]

    return df

# --- Funﾃｧﾃ｣o de Busca de Bonificaﾃｧﾃｵes (MODIFICADA) ---
def buscar_bonificacoes_b3(ticker, empresas_df, data_inicio, data_fim):
    """Busca eventos de bonificaﾃｧﾃ｣o (stock dividends) na B3 usando o CODE da empresa."""
    if not any(char.isdigit() for char in ticker):
        return pd.DataFrame()

    ticker_info = get_ticker_info(ticker, empresas_df)
    if not ticker_info or not ticker_info.get('code'):
        st.warning(f"Cﾃｳdigo (CODE) nﾃ｣o encontrado para o ticker {ticker} na planilha. Nﾃ｣o ﾃｩ possﾃｭvel buscar bonificaﾃｧﾃｵes.")
        return pd.DataFrame()

    code = ticker_info['code']

    # --- ALTERAﾃﾃグ AQUI: Usa curl_cffi ---
    session = curl_requests.Session(impersonate="chrome")

    try:
        params_bonificacoes = {
            "issuingCompany": code,
            "language": "pt-br"
        }
        params_json = json.dumps(params_bonificacoes)
        params_encoded = b64encode(params_json.encode('utf-8')).decode('utf-8')
        url = f'https://sistemaswebb3-listados.b3.com.br/listedCompaniesProxy/CompanyCall/GetListedSupplementCompany/{params_encoded}'
        
        # --- ALTERAﾃﾃグ AQUI: Usa a sessﾃ｣o para fazer a requisiﾃｧﾃ｣o ---
        response = session.get(url, timeout=30)
        response.raise_for_status()

        if not response.content or not response.text.strip():
            return pd.DataFrame()
        try:
            data = response.json()
        except json.JSONDecodeError:
            return pd.DataFrame()

        if not isinstance(data, list) or not data or "stockDividends" not in data[0] or not data[0]["stockDividends"]:
            return pd.DataFrame()

        df = pd.DataFrame(data[0]["stockDividends"])
        if df.empty:
            return pd.DataFrame()

        df['Ticker'] = ticker
        if 'lastDatePrior' in df.columns:
            df['lastDatePrior_dt'] = pd.to_datetime(df['lastDatePrior'], format='%d/%m/%Y', errors='coerce')
            df = df.dropna(subset=['lastDatePrior_dt'])
            df = df[(df['lastDatePrior_dt'] >= data_inicio) & (df['lastDatePrior_dt'] <= data_fim)]
            df = df.drop(columns=['lastDatePrior_dt'])
        else:
            st.warning(f"Coluna 'lastDatePrior' nﾃ｣o encontrada para filtrar datas de bonificaﾃｧﾃｵes de {ticker}.")
            return pd.DataFrame()

        if 'Ticker' in df.columns:
            cols_to_keep = ['Ticker', 'label', 'lastDatePrior', 'factor', 'approvedIn', 'isinCode']
            existing_cols_to_keep = [col for col in cols_to_keep if col in df.columns]
            other_cols = [col for col in df.columns if col not in existing_cols_to_keep]
            df = df[existing_cols_to_keep + other_cols]

        return df

    # --- ALTERAﾃﾃグ AQUI: Captura o erro da biblioteca correta ---
    except curl_requests.errors.RequestsError as e:
        st.error(f"Erro de rede ao buscar bonificaﾃｧﾃｵes para {ticker} (Cﾃｳdigo: {code}): {e}")
        return pd.DataFrame()
    except Exception as e:
        st.error(f"Erro inesperado ao buscar bonificaﾃｧﾃｵes para {ticker} (Cﾃｳdigo: {code}): {e}")
        return pd.DataFrame()

# Patch para cookies do yfinance
def _wrap_cookie(cookie, session):
    if isinstance(cookie, str):
        value = session.cookies.get(cookie)
        return create_cookie(name=cookie, value=value)
    return cookie

def patch_yfdata_cookie_basic():
    original = _data.YfData._get_cookie_basic
    def _patched(self, timeout=30):
        cookie = original(self, timeout)
        return _wrap_cookie(cookie, self._session)
    _data.YfData._get_cookie_basic = _patched

patch_yfdata_cookie_basic()

def buscar_dados_acoes(tickers_input, data_inicio_input, data_fim_input, empresas_df, st=None):
    try:
        data_inicio_str = datetime.strptime(data_inicio_input, "%d/%m/%Y").strftime("%Y-%m-%d")
        data_fim_dt = datetime.strptime(data_fim_input, "%d/%m/%Y")
        data_fim_ajustada_str = (data_fim_dt + timedelta(days=1)).strftime("%Y-%m-%d")
    except ValueError:
        if st:
            st.error("Formato de data invﾃ｡lido. Use dd/mm/aaaa.")
        return {}, ["Formato de data invﾃ｡lido."]

    tickers_list = [ticker.strip().upper() for ticker in tickers_input.split(',') if ticker.strip()]
    dados_acoes_dict = {}
    erros = []

    b3_tickers_set = set()
    if 'Tickers' in empresas_df.columns:
        for t_list in empresas_df['Tickers'].dropna().str.split(','):
            for ticker in t_list:
                if ticker.strip():
                    b3_tickers_set.add(ticker.strip().upper())

    tickers_yf = []
    for ticker in tickers_list:
        if ticker in b3_tickers_set:
            tickers_yf.append(ticker + '.SA')
        else:
            tickers_yf.append(ticker)

    session = curl_requests.Session(impersonate="chrome")

    try:
        if st:
            st.write(f"Buscando preﾃｧos histﾃｳricos para {', '.join(tickers_list)}...")
        else:
            print(f"Buscando preﾃｧos histﾃｳricos para {', '.join(tickers_list)}...")
            
        dados = yf.download(
            tickers=tickers_yf,
            start=data_inicio_str,
            end=data_fim_ajustada_str,
            auto_adjust=False,
            progress=False,
            session=session
        )
    except Exception as e:
        error_type = type(e).__name__
        return {}, [f"Erro ao baixar dados de preﾃｧos: {error_type} - {e}"]
    
    for idx, ticker in enumerate(tickers_list):
        ticker_yf = tickers_yf[idx]
        try:
            if isinstance(dados.columns, pd.MultiIndex):
                if ticker_yf not in dados.columns.get_level_values(1):
                    erros.append(f"Nenhum dado encontrado para {ticker} ({ticker_yf}).")
                    continue
                dados_ticker = dados.xs(key=ticker_yf, axis=1, level=1)
            else:
                if dados.empty:
                    erros.append(f"Nenhum dado encontrado para {ticker} ({ticker_yf}).")
                    continue
                dados_ticker = dados.copy()

            if not dados_ticker.empty:
                dados_ticker = dados_ticker.reset_index()
                dados_ticker = dados_ticker[dados_ticker['Date'] <= data_fim_dt]
                dados_ticker['Date'] = pd.to_datetime(dados_ticker['Date']).dt.strftime('%d/%m/%Y')
                dados_ticker['Ticker'] = ticker

                standard_cols = ['Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume']
                cols_order_start = ['Ticker', 'Date']
                existing_standard_cols = [col for col in standard_cols if col in dados_ticker.columns]
                other_cols = [col for col in dados_ticker.columns if col not in cols_order_start and col not in existing_standard_cols]
                final_cols_order = cols_order_start + existing_standard_cols + other_cols
                dados_ticker = dados_ticker[final_cols_order]

                dados_acoes_dict[ticker] = dados_ticker
            else:
                erros.append(f"Sem dados de preﾃｧos histﾃｳricos encontrados para {ticker} ({ticker_yf}) no perﾃｭodo.")
        except Exception as e:
            error_type = type(e).__name__
            erros.append(f"Erro ao processar dados de preﾃｧos para {ticker} ({ticker_yf}): {error_type} - {e}")

    return dados_acoes_dict, erros

# ============================================
# Interface do Streamlit
# ============================================
st.set_page_config(layout="wide")
st.title('Consulta Dados de Mercado B3 e Preﾃｧo Yahoo Finance')

# --- Carrega o DataFrame de empresas ---
df_empresas = carregar_empresas()

if df_empresas.empty:
    st.error("Nﾃ｣o foi possﾃｭvel carregar a lista de empresas. Verifique a URL ou o arquivo. A aplicaﾃｧﾃ｣o nﾃ｣o pode continuar.")
    st.stop()

# --- Entradas do Usuﾃ｡rio ---
col1, col2 = st.columns(2)
with col1:
    tickers_input = st.text_input("Digite os tickers separados por vﾃｭrgula (ex: PETR4, VALE3, MGLU3, ITUB4):", key="tickers")
with col2:
    tipos_dados_selecionados = st.multiselect(
        "Selecione os dados que deseja buscar:",
        ["Preﾃｧos Histﾃｳricos (Yahoo Finance)", "Dividendos (B3)", "Bonificaﾃｧﾃｵes (B3)"],
        default=["Preﾃｧos Histﾃｳricos (Yahoo Finance)"],
        key="data_types"
    )

col3, col4 = st.columns(2)
with col3:
    data_inicio_input = st.text_input("Data de inﾃｭcio (dd/mm/aaaa):", key="date_start")
with col4:
    data_fim_input = st.text_input("Data de fim (dd/mm/aaaa):", key="date_end")

# --- Inicializaﾃｧﾃ｣o do Session State ---
if 'dados_buscados' not in st.session_state:
    st.session_state.dados_buscados = False
    st.session_state.todos_dados_acoes = {}
    st.session_state.todos_dados_dividendos = {}
    st.session_state.todos_dados_bonificacoes = {}
    st.session_state.erros_gerais = []

# --- Botﾃ｣o e Lﾃｳgica Principal ---
if st.button('Buscar Dados', key="search_button"):
    st.session_state.dados_buscados = False
    st.session_state.todos_dados_acoes = {}
    st.session_state.todos_dados_dividendos = {}
    st.session_state.todos_dados_bonificacoes = {}
    st.session_state.erros_gerais = []

    if tickers_input and data_inicio_input and data_fim_input and tipos_dados_selecionados:
        try:
            data_inicio_dt = datetime.strptime(data_inicio_input, "%d/%m/%Y")
            data_fim_dt = datetime.strptime(data_fim_input, "%d/%m/%Y")
            if data_inicio_dt > data_fim_dt:
                st.error("A data de inﾃｭcio nﾃ｣o pode ser posterior ﾃ data de fim.")
                st.stop()
        except ValueError:
            st.error("Formato de data invﾃ｡lido. Use dd/mm/aaaa.")
            st.stop()

        tickers_list = sorted(list(set([ticker.strip().upper() for ticker in tickers_input.split(',') if ticker.strip()])))

        with st.spinner('Buscando dados... Por favor, aguarde.'):
            if "Preﾃｧos Histﾃｳricos (Yahoo Finance)" in tipos_dados_selecionados:
                dados_acoes_dict, erros_acoes = buscar_dados_acoes(tickers_input, data_inicio_input, data_fim_input, empresas_df=df_empresas)
                if dados_acoes_dict:
                    st.session_state.todos_dados_acoes = dados_acoes_dict
                if erros_acoes:
                    st.session_state.erros_gerais.extend(erros_acoes)

            if "Dividendos (B3)" in tipos_dados_selecionados:
                dividendos_temp = {}
                for ticker in tickers_list:
                    df_dividendos = buscar_dividendos_b3(ticker, df_empresas, data_inicio_dt, data_fim_dt)
                    if not df_dividendos.empty:
                        dividendos_temp[ticker] = df_dividendos
                st.session_state.todos_dados_dividendos = dividendos_temp

            if "Bonificaﾃｧﾃｵes (B3)" in tipos_dados_selecionados:
                bonificacoes_temp = {}
                for ticker in tickers_list:
                    df_bonificacoes = buscar_bonificacoes_b3(ticker, df_empresas, data_inicio_dt, data_fim_dt)
                    if not df_bonificacoes.empty:
                        bonificacoes_temp[ticker] = df_bonificacoes
                st.session_state.todos_dados_bonificacoes = bonificacoes_temp
        
        st.session_state.dados_buscados = True
    else:
        st.warning("Por favor, preencha todos os campos: tickers, datas e selecione ao menos um tipo de dado.")

# --- EXIBIﾃﾃグ E DOWNLOAD ---
if st.session_state.get('dados_buscados', False):
    if st.session_state.erros_gerais:
        for erro in st.session_state.erros_gerais:
            st.warning(erro)

    if st.session_state.todos_dados_acoes:
        st.subheader("1. Preﾃｧos Histﾃｳricos (Yahoo Finance)")
        df_acoes_agrupado = pd.concat(st.session_state.todos_dados_acoes.values(), ignore_index=True)
        st.dataframe(df_acoes_agrupado)

    if st.session_state.todos_dados_dividendos:
        st.subheader("2. Dividendos (B3)")
        df_dividendos_agrupado = pd.concat(st.session_state.todos_dados_dividendos.values(), ignore_index=True)
        st.dataframe(df_dividendos_agrupado)

    if st.session_state.todos_dados_bonificacoes:
        st.subheader("3. Bonificaﾃｧﾃｵes (B3)")
        df_bonificacoes_agrupado = pd.concat(st.session_state.todos_dados_bonificacoes.values(), ignore_index=True)
        st.dataframe(df_bonificacoes_agrupado)

    if not st.session_state.todos_dados_acoes and not st.session_state.todos_dados_dividendos and not st.session_state.todos_dados_bonificacoes:
        st.info("Nenhum dado encontrado para os critﾃｩrios selecionados.")
    else:
        st.subheader("踏 Download dos Dados em Excel")
        formato_excel = st.radio(
            "Escolha o formato do arquivo Excel:",
            ("Agrupar por tipo de dado (uma aba para Preﾃｧos, outra para Dividendos, etc.)",
             "Separar por ticker e tipo (ex: Precos_PETR4, Div_VALE3, etc.)"),
            key="excel_format"
        )

        nome_arquivo = f"dados_mercado_{data_inicio_input.replace('/','')}_{data_fim_input.replace('/','')}_{datetime.now().strftime('%H%M')}.xlsx"
        try:
            from io import BytesIO
            output = BytesIO()
            with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                if formato_excel.startswith("Agrupar"):
                    if st.session_state.todos_dados_acoes:
                        pd.concat(st.session_state.todos_dados_acoes.values(), ignore_index=True).to_excel(writer, sheet_name="Precos_Historicos", index=False)
                    if st.session_state.todos_dados_dividendos:
                        pd.concat(st.session_state.todos_dados_dividendos.values(), ignore_index=True).to_excel(writer, sheet_name="Dividendos", index=False)
                    if st.session_state.todos_dados_bonificacoes:
                        pd.concat(st.session_state.todos_dados_bonificacoes.values(), ignore_index=True).to_excel(writer, sheet_name="Bonificacoes", index=False)
                
                else: # Separar por ticker e tipo
                    if st.session_state.todos_dados_acoes:
                        for ticker, df in st.session_state.todos_dados_acoes.items():
                            df.to_excel(writer, sheet_name=f"Precos_{ticker[:25]}", index=False)
                    if st.session_state.todos_dados_dividendos:
                        for ticker, df in st.session_state.todos_dados_dividendos.items():
                            df.to_excel(writer, sheet_name=f"Div_{ticker[:25]}", index=False)
                    if st.session_state.todos_dados_bonificacoes:
                        for ticker, df in st.session_state.todos_dados_bonificacoes.items():
                            df.to_excel(writer, sheet_name=f"Bonif_{ticker[:25]}", index=False)
            
            excel_data = output.getvalue()

            st.download_button(
                label="Baixar arquivo Excel",
                data=excel_data,
                file_name=nome_arquivo,
                mime='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet'
            )
        except Exception as e:
            st.error(f"Erro ao gerar o arquivo Excel: {e}")

# --- Rodapﾃｩ ---
st.markdown("""
---
**Fontes dos dados:**
- Preﾃｧos Histﾃｳricos: [Yahoo Finance](https://finance.yahoo.com)
- Dividendos e Eventos societﾃ｡rios: [API B3](https://www.b3.com.br) 
""")
